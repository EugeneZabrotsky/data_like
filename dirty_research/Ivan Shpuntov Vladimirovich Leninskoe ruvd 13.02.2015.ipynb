{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from catboost.utils import create_cd\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from bayes_opt.observer import JSONLogger\n",
    "from bayes_opt.event import Events\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['customer_id', 'story_id',\n",
    "                'product_0', 'product_1', 'product_2', 'product_3', 'product_4', 'product_5', 'product_6',\n",
    "                'marital_status_cd', 'job_position_cd', 'prod_not_nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DATA_PATH = config.get_data_path()\n",
    "\n",
    "TRAIN_FEATURES = DATA_PATH / 'train_features.csv'\n",
    "TEST_FEATURES = DATA_PATH / 'test_features.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_FEATURES, index_col=0, parse_dates=['event_dttm'])\n",
    "test_df = pd.read_csv(TEST_FEATURES, index_col=0, parse_dates=['event_dttm'])\n",
    "\n",
    "train_df['nearest_story_seconds_before'] = train_df['nearest_story_seconds_before'].abs()\n",
    "test_df['nearest_story_seconds_before'] = test_df['nearest_story_seconds_before'].abs()\n",
    "\n",
    "train_df = train_df.fillna(-999)\n",
    "test_df = test_df.fillna(-999)\n",
    "\n",
    "train_df\n",
    "\n",
    "train_df = train_df.sort_values('event_dttm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['event']\n",
    "train_df.drop(['event', 'event_dttm', 'first_session_dttm'],inplace=True,axis=1)\n",
    "test_df.drop(['event', 'event_dttm', 'first_session_dttm'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def muiltiEncoder(df,cat_features_init,multi_target,sm = 5):\n",
    "#     encoder = TargetEncoder(cols = cat_features_init,smoothing=sm)\n",
    "#     vals = []\n",
    "#     for i in range(multi_target.shape[1]):\n",
    "#         val = encoder.fit_transform(df[cat_features_init],multi_target[:,i])\n",
    "#         val.columns = [column + '_target_encode_' + str(i) for column in val.columns]\n",
    "#         vals += [val]\n",
    "#     df_drop = df.drop(cat_features_init,axis=1)\n",
    "#     return pd.concat(vals + [df_drop],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_enc = muiltiEncoder(X_train,cat_features_init,y_train)\n",
    "# X_val_enc = muiltiEncoder(X_val,cat_features_init,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_df,y,test_size = 0.2,shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa = {\n",
    "    0:10,\n",
    "    1:0.1,\n",
    "    2:0.1,\n",
    "    3:0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train, y_train,\n",
    "                        weight=y_train.astype(int).map(mapa), free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train,\n",
    "                       weight=y_val.astype(int).map(mapa), free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's multi_logloss: 1.32839\n",
      "[2]\tvalid_0's multi_logloss: 1.29622\n",
      "[3]\tvalid_0's multi_logloss: 1.2688\n",
      "[4]\tvalid_0's multi_logloss: 1.24883\n",
      "[5]\tvalid_0's multi_logloss: 1.22752\n",
      "[6]\tvalid_0's multi_logloss: 1.2071\n",
      "[7]\tvalid_0's multi_logloss: 1.19033\n",
      "[8]\tvalid_0's multi_logloss: 1.17454\n",
      "[9]\tvalid_0's multi_logloss: 1.16031\n",
      "[10]\tvalid_0's multi_logloss: 1.14822\n",
      "[11]\tvalid_0's multi_logloss: 1.13724\n",
      "[12]\tvalid_0's multi_logloss: 1.12913\n",
      "[13]\tvalid_0's multi_logloss: 1.12014\n",
      "[14]\tvalid_0's multi_logloss: 1.1122\n",
      "[15]\tvalid_0's multi_logloss: 1.10633\n",
      "[16]\tvalid_0's multi_logloss: 1.09987\n",
      "[17]\tvalid_0's multi_logloss: 1.09382\n",
      "[18]\tvalid_0's multi_logloss: 1.08757\n",
      "[19]\tvalid_0's multi_logloss: 1.08168\n",
      "[20]\tvalid_0's multi_logloss: 1.07722\n",
      "[21]\tvalid_0's multi_logloss: 1.0729\n",
      "[22]\tvalid_0's multi_logloss: 1.06942\n",
      "[23]\tvalid_0's multi_logloss: 1.06521\n",
      "[24]\tvalid_0's multi_logloss: 1.06315\n",
      "[25]\tvalid_0's multi_logloss: 1.06135\n",
      "[26]\tvalid_0's multi_logloss: 1.05747\n",
      "[27]\tvalid_0's multi_logloss: 1.05419\n",
      "[28]\tvalid_0's multi_logloss: 1.05225\n",
      "[29]\tvalid_0's multi_logloss: 1.04967\n",
      "[30]\tvalid_0's multi_logloss: 1.04799\n",
      "[31]\tvalid_0's multi_logloss: 1.04552\n",
      "[32]\tvalid_0's multi_logloss: 1.04355\n",
      "[33]\tvalid_0's multi_logloss: 1.04157\n",
      "[34]\tvalid_0's multi_logloss: 1.04029\n",
      "[35]\tvalid_0's multi_logloss: 1.03917\n",
      "[36]\tvalid_0's multi_logloss: 1.03693\n",
      "[37]\tvalid_0's multi_logloss: 1.03509\n",
      "[38]\tvalid_0's multi_logloss: 1.03338\n",
      "[39]\tvalid_0's multi_logloss: 1.03217\n",
      "[40]\tvalid_0's multi_logloss: 1.03083\n",
      "[41]\tvalid_0's multi_logloss: 1.02917\n",
      "[42]\tvalid_0's multi_logloss: 1.0282\n",
      "[43]\tvalid_0's multi_logloss: 1.02759\n",
      "[44]\tvalid_0's multi_logloss: 1.02761\n",
      "[45]\tvalid_0's multi_logloss: 1.02754\n",
      "[46]\tvalid_0's multi_logloss: 1.02599\n",
      "[47]\tvalid_0's multi_logloss: 1.02508\n",
      "[48]\tvalid_0's multi_logloss: 1.02407\n",
      "[49]\tvalid_0's multi_logloss: 1.02406\n",
      "[50]\tvalid_0's multi_logloss: 1.02363\n",
      "[51]\tvalid_0's multi_logloss: 1.02336\n",
      "[52]\tvalid_0's multi_logloss: 1.02324\n",
      "[53]\tvalid_0's multi_logloss: 1.02356\n",
      "[54]\tvalid_0's multi_logloss: 1.02358\n",
      "[55]\tvalid_0's multi_logloss: 1.02425\n",
      "[56]\tvalid_0's multi_logloss: 1.02347\n",
      "[57]\tvalid_0's multi_logloss: 1.02292\n",
      "[58]\tvalid_0's multi_logloss: 1.02252\n",
      "[59]\tvalid_0's multi_logloss: 1.02279\n",
      "[60]\tvalid_0's multi_logloss: 1.02285\n",
      "[61]\tvalid_0's multi_logloss: 1.02212\n",
      "[62]\tvalid_0's multi_logloss: 1.0215\n",
      "[63]\tvalid_0's multi_logloss: 1.02093\n",
      "[64]\tvalid_0's multi_logloss: 1.0207\n",
      "[65]\tvalid_0's multi_logloss: 1.02062\n",
      "[66]\tvalid_0's multi_logloss: 1.02038\n",
      "[67]\tvalid_0's multi_logloss: 1.02015\n",
      "[68]\tvalid_0's multi_logloss: 1.02027\n",
      "[69]\tvalid_0's multi_logloss: 1.02027\n",
      "[70]\tvalid_0's multi_logloss: 1.0203\n",
      "[71]\tvalid_0's multi_logloss: 1.01996\n",
      "[72]\tvalid_0's multi_logloss: 1.02024\n",
      "[73]\tvalid_0's multi_logloss: 1.01993\n",
      "[74]\tvalid_0's multi_logloss: 1.02036\n",
      "[75]\tvalid_0's multi_logloss: 1.02099\n",
      "[76]\tvalid_0's multi_logloss: 1.02084\n",
      "[77]\tvalid_0's multi_logloss: 1.02087\n",
      "[78]\tvalid_0's multi_logloss: 1.02092\n",
      "[79]\tvalid_0's multi_logloss: 1.02072\n",
      "[80]\tvalid_0's multi_logloss: 1.02088\n",
      "[81]\tvalid_0's multi_logloss: 1.02021\n",
      "[82]\tvalid_0's multi_logloss: 1.02008\n",
      "[83]\tvalid_0's multi_logloss: 1.02043\n",
      "[84]\tvalid_0's multi_logloss: 1.02085\n",
      "[85]\tvalid_0's multi_logloss: 1.02116\n",
      "[86]\tvalid_0's multi_logloss: 1.01993\n",
      "[87]\tvalid_0's multi_logloss: 1.01932\n",
      "[88]\tvalid_0's multi_logloss: 1.0188\n",
      "[89]\tvalid_0's multi_logloss: 1.01854\n",
      "[90]\tvalid_0's multi_logloss: 1.01801\n",
      "[91]\tvalid_0's multi_logloss: 1.01781\n",
      "[92]\tvalid_0's multi_logloss: 1.01827\n",
      "[93]\tvalid_0's multi_logloss: 1.01867\n",
      "[94]\tvalid_0's multi_logloss: 1.01914\n",
      "[95]\tvalid_0's multi_logloss: 1.0194\n",
      "[96]\tvalid_0's multi_logloss: 1.01921\n",
      "[97]\tvalid_0's multi_logloss: 1.01919\n",
      "[98]\tvalid_0's multi_logloss: 1.01898\n",
      "[99]\tvalid_0's multi_logloss: 1.01936\n",
      "[100]\tvalid_0's multi_logloss: 1.01964\n",
      "[101]\tvalid_0's multi_logloss: 1.01922\n",
      "[102]\tvalid_0's multi_logloss: 1.01895\n",
      "[103]\tvalid_0's multi_logloss: 1.01882\n",
      "[104]\tvalid_0's multi_logloss: 1.01893\n",
      "[105]\tvalid_0's multi_logloss: 1.01891\n",
      "[106]\tvalid_0's multi_logloss: 1.01859\n",
      "[107]\tvalid_0's multi_logloss: 1.01819\n",
      "[108]\tvalid_0's multi_logloss: 1.0182\n",
      "[109]\tvalid_0's multi_logloss: 1.0182\n",
      "[110]\tvalid_0's multi_logloss: 1.0178\n",
      "[111]\tvalid_0's multi_logloss: 1.01757\n",
      "[112]\tvalid_0's multi_logloss: 1.01735\n",
      "[113]\tvalid_0's multi_logloss: 1.01759\n",
      "[114]\tvalid_0's multi_logloss: 1.01776\n",
      "[115]\tvalid_0's multi_logloss: 1.01777\n",
      "[116]\tvalid_0's multi_logloss: 1.01777\n",
      "[117]\tvalid_0's multi_logloss: 1.01796\n",
      "[118]\tvalid_0's multi_logloss: 1.01741\n",
      "[119]\tvalid_0's multi_logloss: 1.01746\n",
      "[120]\tvalid_0's multi_logloss: 1.01783\n",
      "[121]\tvalid_0's multi_logloss: 1.01746\n",
      "[122]\tvalid_0's multi_logloss: 1.01729\n",
      "[123]\tvalid_0's multi_logloss: 1.01733\n",
      "[124]\tvalid_0's multi_logloss: 1.0172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-28cb4fbd7b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlgb_eval\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# eval training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 categorical_feature=[feature_name.index(feature) for feature in cat_features])\n\u001b[0m",
      "\u001b[0;32m/data/eazabrotsky/anaconda3/envs/ds/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/eazabrotsky/anaconda3/envs/ds/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_class': 4,\n",
    "    'num_leaves': 20,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "feature_name = X_train.columns.values.tolist()\n",
    "\n",
    "print('Starting training...')\n",
    "# feature_name and categorical_feature\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=lgb_eval,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[feature_name.index(feature) for feature in cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
