{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "import config\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "DATA_PATH = config.get_data_path()\n",
    "\n",
    "TRAIN_FEATURES = DATA_PATH / 'train_features.csv'\n",
    "TEST_FEATURES = DATA_PATH / 'test_features.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_FEATURES, index_col=0, parse_dates=['event_dttm'])\n",
    "test_df = pd.read_csv(TEST_FEATURES, index_col=0, parse_dates=['event_dttm'])\n",
    "\n",
    "def add_this_story_counter(full_df, mode='after'):\n",
    "    already_seen = defaultdict(int)\n",
    "    result= np.zeros(len(full_df))\n",
    "    length = full_df.shape[0]\n",
    "    \n",
    "    for j in range(length):\n",
    "        i = (length - j - 1) if mode == 'after' else j\n",
    "        current_id = full_df.customer_id.iloc[i] * 20000 + full_df.story_id.iloc[i]\n",
    "        result[i] = already_seen[current_id]\n",
    "        already_seen[current_id] += 1\n",
    "\n",
    "    full_df[f'this_story_{mode}_counter'] = result\n",
    "    return full_df\n",
    "\n",
    "def add_story_counter(full_df, mode='after'):\n",
    "    already_seen = defaultdict(int)\n",
    "    result= np.zeros(len(full_df))\n",
    "    length = full_df.shape[0]\n",
    "\n",
    "    for j in range(length):\n",
    "        i = (length - j - 1) if mode == 'after' else j\n",
    "        current_id = full_df.customer_id.iloc[i]\n",
    "        result[i] = already_seen[current_id]\n",
    "        already_seen[current_id] += 1\n",
    "\n",
    "    full_df[f'stories_{mode}_counter'] = result\n",
    "    return full_df\n",
    "\n",
    "def near_story_time(full_df, mode='after'):\n",
    "    current = dict()\n",
    "    result_array = np.zeros(len(full_df))\n",
    "    length = full_df.shape[0]\n",
    "\n",
    "    for j in range(length):\n",
    "        i = (length - j - 1) if mode == 'after' else j\n",
    "        current_id = full_df.customer_id.iloc[i]\n",
    "        \n",
    "        result = np.NaN\n",
    "        curtime = full_df['event_dttm'].iloc[i]\n",
    "        if current_id in current:\n",
    "            if (current[current_id][0] - curtime).total_seconds() == 0:\n",
    "                if (current[current_id][1] is not np.NaN):\n",
    "                    result = (current[current_id][1] - curtime).total_seconds()\n",
    "            else:\n",
    "                result = (current[current_id][0] - curtime).total_seconds()\n",
    "                current[current_id] = (curtime, current[current_id][0])\n",
    "        else:\n",
    "            current[current_id] = (curtime, np.NaN)\n",
    "            \n",
    "        result_array[i] = result\n",
    "\n",
    "    full_df[f'nearest_story_seconds_{mode}'] = result\n",
    "    \n",
    "    return full_df\n",
    "\n",
    "def add_story_counters_features(train_df, test_df):\n",
    "    dttm_thresh = train_df['event_dttm'].max()\n",
    "    full_df = pd.concat([train_df, test_df], sort=False)\n",
    "    full_df = full_df.sort_values('event_dttm')\n",
    "\n",
    "    full_df = add_story_counter(full_df, mode='before')\n",
    "    full_df = add_story_counter(full_df, mode='after')\n",
    "    full_df = add_this_story_counter(full_df, mode='before')\n",
    "    full_df = add_this_story_counter(full_df, mode='after')\n",
    "    full_df = near_story_time(full_df, mode='before')\n",
    "    full_df = near_story_time(full_df, mode='after')\n",
    "\n",
    "    full_df = full_df.sort_index()\n",
    "    full_df['stories_at_all'] = full_df['stories_before_counter'] + full_df['stories_after_counter']\n",
    "    full_df['this_story_at_all'] = full_df['this_story_before_counter'] + full_df['this_story_after_counter']\n",
    "    \n",
    "    \n",
    "    train_df = full_df[full_df['event_dttm'] <= dttm_thresh]\n",
    "    test_df = full_df[full_df['event_dttm'] > dttm_thresh]\n",
    "    \n",
    "    return train_df.sort_index(), test_df.sort_index()\n",
    "\n",
    "train_df, test_df = add_story_counters_features(train_df, test_df)\n",
    "\n",
    "# train_df.to_csv(TRAIN_FEATURES)\n",
    "# test_df.to_csv(TEST_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "dttm_thresh = train_df['event_dttm'].max()\n",
    "full_df = pd.concat([train_df, test_df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = full_df.sort_values('event_dttm').copy()\n",
    "temp_df['ones'] = np.ones(temp_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stories = (\n",
    "    temp_df\n",
    "    .groupby(['customer_id', 'event_dttm'])['story_id']\n",
    "    .nunique()\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (\n",
    "    temp_df\n",
    "    .groupby(['customer_id', 'event_dttm'])['ones']\n",
    "    .apply(sum)\n",
    "    .reset_index()\n",
    "    .sort_values('event_dttm')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['ones_for_group'] = np.ones(a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['group_number'] = a.groupby('customer_id')['ones_for_group'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.merge(temp_df, a, on=['customer_id', 'event_dttm']).sort_values('event_dttm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.merge(temp_df, unique_stories, on=['customer_id', 'event_dttm']).sort_values('event_dttm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.drop(['ones_x', 'ones_y', 'ones_for_group'], axis=1)\n",
    "temp_df['story_id'] = temp_df['story_id_x']\n",
    "temp_df['unique_in_group'] = temp_df['story_id_y']\n",
    "temp_df = temp_df.drop(['story_id_y', 'story_id_x', 'group_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = full_df[full_df['event_dttm'] <= dttm_thresh]\n",
    "test_df = full_df[full_df['event_dttm'] > dttm_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sort_index().to_csv(TRAIN_FEATURES)\n",
    "test_df.sort_index().to_csv(TEST_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'story_id', 'event_dttm', 'event', 'weekday', 'day',\n",
       "       'hour', 'minute', 'is_weeked', 'product_0', 'product_1', 'product_2',\n",
       "       'product_3', 'product_4', 'product_5', 'product_6', 'gender_cd', 'age',\n",
       "       'marital_status_cd', 'children_cnt', 'job_position_cd', 'prod_not_nan',\n",
       "       'prod_sum_opn', 'prod_sum_utl', 'prod_sum_cls', 'num_pages', 'num_urls',\n",
       "       'num_elements', 'mean_font_size', 'text_amount', 'clusters', 'neutral',\n",
       "       'negative', 'skip', 'speech', 'positive', 'num_messages', 'text_len',\n",
       "       'num_guids', 'sum_amount', 'mean_amount', 'num_trans', 'std_amount',\n",
       "       'std_amount_normalized', 'sum_amount_if_retail_shops',\n",
       "       'sum_amount_if_retail_shops_percentage', 'sum_amount_if_other_shops',\n",
       "       'sum_amount_if_other_shops_percentage',\n",
       "       'sum_amount_if_professional_service',\n",
       "       'sum_amount_if_professional_service_percentage',\n",
       "       'sum_amount_if_transport', 'sum_amount_if_transport_percentage',\n",
       "       'sum_amount_if_unknown', 'sum_amount_if_unknown_percentage',\n",
       "       'sum_amount_if_entertainment', 'sum_amount_if_entertainment_percentage',\n",
       "       'sum_amount_if_business_service',\n",
       "       'sum_amount_if_business_service_percentage', 'sum_amount_if_clothes',\n",
       "       'sum_amount_if_clothes_percentage', 'sum_amount_if_personal_service',\n",
       "       'sum_amount_if_personal_service_percentage',\n",
       "       'sum_amount_if_utility_service',\n",
       "       'sum_amount_if_utility_service_percentage', 'sum_amount_if_auto_rental',\n",
       "       'sum_amount_if_auto_rental_percentage', 'sum_amount_if_wholesale',\n",
       "       'sum_amount_if_wholesale_percentage', 'sum_amount_if_hotels',\n",
       "       'sum_amount_if_hotels_percentage', 'sum_amount_if_repair_service',\n",
       "       'sum_amount_if_repair_service_percentage',\n",
       "       'sum_amount_if_mail_phone_sales',\n",
       "       'sum_amount_if_mail_phone_sales_percentage',\n",
       "       'sum_amount_if_state_service', 'sum_amount_if_state_service_percentage',\n",
       "       'sum_amount_if_service', 'sum_amount_if_service_percentage',\n",
       "       'sum_amount_if_airlines', 'sum_amount_if_airlines_percentage',\n",
       "       'sum_amount_if_membership_organizations',\n",
       "       'sum_amount_if_membership_organizations_percentage',\n",
       "       'sum_amount_if_contract_service',\n",
       "       'sum_amount_if_contract_service_percentage', 'answer_id',\n",
       "       'this_story_after_counter', 'this_story_before_counter',\n",
       "       'stories_before_counter', 'stories_after_counter',\n",
       "       'nearest_story_seconds_before', 'nearest_story_seconds_after',\n",
       "       'stories_at_all', 'this_story_at_all', 'watched_prev', 'watched_post',\n",
       "       'watched_in_window_day', 'watched_in_window_now',\n",
       "       'watched_in_window_day_excluding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
